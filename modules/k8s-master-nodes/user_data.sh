#! /bin/bash
# Redirect all output with -> exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1
exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1
sudo yum update -y
sudo yum install git curl tree socat jq -y

# Set the correct hostname (needed for aws kubernetes provider - Ubuntu servers))
hostnamectl set-hostname `curl http://169.254.169.254/latest/meta-data/local-hostname`

# Add AWS Kubernetes provider config file
sudo mkdir -p /etc/kubernetes/
sudo cat > /etc/kubernetes/aws.yml <<EOF
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
networking:
  serviceSubnet: "10.20.0.0/16"
  podSubnet: "10.20.0.0/16"
  pod-network-cidr: 10.20.0.0/16
apiServer:
  extraArgs:
    cloud-provider: "aws"
controllerManager:
  extraArgs:
    cloud-provider: "aws"
EOF

# Adding env var to path to make kubectl command work"
sudo echo 'PATH=$PATH:/usr/local/bin'  | tee -a /root/.bashrc /home/ec2-user/.bashrc
sudo echo 'export PATH=$PATH'  | tee -a /root/.bashrc /home/ec2-user/.bashrc 

# Enabling shell autocompletion.
sudo yum install bash-completion -y
sudo echo 'source <(kubectl completion bash)' | tee -a /root/.bashrc /home/ec2-user/.bashrc
sudo chown ec2-user:ec2-user /usr/share/bash-completion/bash_completion

# Load profile
source ~/.bashrc

# Installing kubectx kubens helm
sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
sudo ln -s /opt/kubectx/kubectx /usr/local/bin/kubectx
sudo ln -s /opt/kubectx/kubens /usr/local/bin/kubens
sudo curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 > get_helm.sh
sudo chmod 700 get_helm.sh
sudo ./get_helm.sh
helm repo add incubator https://kubernetes-charts-incubator.storage.googleapis.com/
helm repo update
# The other repo does not contain the nginx-controller as of this moment.
sudo sudo mkdir -p /var/tmp/helm && git clone https://github.com/helm/charts.git /var/tmp/helm

# Install kubectl, kubeadm, docker
sudo echo [kubernetes] > /etc/yum.repos.d/kubernetes.repo
sudo echo name=Kubernetes >> /etc/yum.repos.d/kubernetes.repo
sudo echo baseurl=https\://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 >> /etc/yum.repos.d/kubernetes.repo
sudo echo enabled=1 >> /etc/yum.repos.d/kubernetes.repo
sudo echo gpgcheck=1 >> /etc/yum.repos.d/kubernetes.repo
sudo echo repo_gpgcheck=0 >> /etc/yum.repos.d/kubernetes.repo
sudo echo gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg >> /etc/yum.repos.d/kubernetes.repo

sudo yum install kubelet kubeadm kubectl docker -y
sudo systemctl restart docker && systemctl enable docker
sudo systemctl restart kubelet && systemctl enable kubelet.service

# Kubernetes TLS bootstrapping
# Place the certificate on the worker and master node: /etc/kubernetes/pki/ca.crt
sudo mkdir -p /etc/kubernetes/pki
aws ssm get-parameter --name KUBERNETES_CA_CERT --region eu-west-1 --with-decryption | jq -r .Parameter.Value > /etc/kubernetes/pki/ca.crt
aws ssm get-parameter --name KUBERNETES_CA_KEY --region eu-west-1 --with-decryption | jq -r .Parameter.Value > /etc/kubernetes/pki/ca.key

# Start Kubeadm cluster
# Starting to initialise kubeadm_master
#sudo kubeadm init --pod-network-cidr=10.20.0.0/16
sudo kubeadm init --config /etc/kubernetes/aws.yml
sudo mkdir -p /root/.kube
sudo cp -i /etc/kubernetes/admin.conf /root/.kube/config
sudo kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml

# Add the bootstrap token on the master node
# But first get the bootstrap token from ssm
export token_id=`aws ssm get-parameter --name KUBERNETES_BOOTSTRAP_TOKEN_ID --region eu-west-1 --with-decryption | jq -r .Parameter.Value`
export token_secret=`aws ssm get-parameter --name KUBERNETES_BOOTSTRAP_TOKEN_SECRET --region eu-west-1 --with-decryption | jq -r .Parameter.Value`
sudo cat > ~/.bootstrap_token <<EOF
apiVersion: v1
kind: Secret
metadata:
  # Name MUST be of form "bootstrap-token-<token id>"
  name: bootstrap-token-02501g
  namespace: kube-system

# Type MUST be 'bootstrap.kubernetes.io/token'
type: bootstrap.kubernetes.io/token
stringData:
  # Human readable description. Optional.
  description: "The default bootstrap token generated by 'kubeadm init'."
  # Token ID and secret. Required.
  token-id: ${token_id}
  token-secret: ${token_secret}
  # Expiration. Optional.
  expiration: 2025-01-01T03:22:11Z
  # Allowed usages.
  usage-bootstrap-authentication: "true"
  usage-bootstrap-signing: "true"
  # Extra groups to authenticate the token as. Must start with "system:bootstrappers:"
  auth-extra-groups: system:bootstrappers:worker,system:bootstrappers:ingress
EOF
sudo kubectl apply -f ~/.bootstrap_token
sudo rm -rf ~/.bootstrap_token

# Set the necesary bootstrap permissions on the master
sudo cat > ~/.cluster_bootstrap_permissions <<EOF
---
# enable bootstrapping nodes to create CSR
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: create-csrs-for-bootstrapping
subjects:
- kind: Group
  name: system:bootstrappers
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:node-bootstrapper
  apiGroup: rbac.authorization.k8s.io
---
# Approve all CSRs for the group "system:bootstrappers"
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: auto-approve-csrs-for-group
subjects:
- kind: Group
  name: system:bootstrappers
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient
  apiGroup: rbac.authorization.k8s.io
---
# Approve renewal CSRs for the group "system:nodes"
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: auto-approve-renewals-for-nodes
subjects:
- kind: Group
  name: system:nodes
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient
  apiGroup: rbac.authorization.k8s.io
EOF
sudo kubectl apply -f ~/.cluster_bootstrap_permissions
sudo rm -rf ~/.cluster_bootstrap_permissions

# Provision the ingress controllerManager. The default helm repo does not contain the Chart for the nginx-ingress controller.
helm install /var/tmp/helm/stable/nginx-ingress --set controller.publishService.enabled='$(POD_NAMESPACE)/ingress' --generate-name
